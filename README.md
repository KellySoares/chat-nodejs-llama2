# Chat conversacional integrado com o LLAMA2
√â um sistema simples de chat conversacional integrado com o modelo de linguagem **LLAMA 2** para
processar e responder entradas de texto. 

## ‚ú® Tecnologias utilizadas

* Node.js v20.10.0
* NPM 10.5.0
* Visual Studio code
* Postman for Windows
* Docker 

## ‚ú® REST Endpoint da Microsoft Azure
Com o Microsoft Azure, voc√™ pode acessar o [Llama 2](https://llama.meta.com/get-started#hosting) atrav√©s dos cat√°logos de Modelos do Azure que √© um centro para explorar cole√ß√µes de modelos b√°sicos. Neste link [Introdu√ß√£o do llama 2 no Azure](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/introducing-llama-2-on-azure/ba-p/3881233) √© poss√≠vel verificar mais detalhes a respeito da REST Endpoint utilizada 

## ‚ú® Utiliza√ß√£o do Socket.IO 
Socket.IO √© uma biblioteca JavaScript para comunica√ß√£o bidirecional em tempo real entre clientes web e servidores. Tem duas partes: uma biblioteca do lado do cliente para navegadores e outra do lado do servidor para Node.js, possibilitando comunica√ß√£o baseada em eventos em tempo real.

## ‚ú® Executando o sistema de chat conversacional 

#### Clone este reposit√≥rio em uma pasta de sua prefer√™ncia
```bash
$ git clone https://github.com/KellySoares/chat-nodejs-llama2.git
```

#### Acesse a pasta
```bash
$ cd chat-nodejs-llama2
```

#### Para acesso a REST Endpoint

Renomeie o arquivo _env.exemple para .env e edite as configura√ß√µes necess√°rias como:
- REST_ENDPOINT (A entrada de infer√™ncia padr√£o do Azure ML. Este caminho √© usado pela UI do AzureML.)
- CHAVE (Chave fornecida para utiliza√ß√£o das REST Endpoint)

**Existe duas formas de execu√ß√£o deste sistema**
- Utilizando Docker (Recomendado)
- Direto na m√°quina local

#### üé≤ Executar utilizando Docker
- Porque o Docker? 
    O Docker √© uma ferramenta que cria containers para separar configura√ß√µes e l√≥gica de aplica√ß√µes, evitando conflitos entre elas e garantindo consist√™ncia nos ambientes de desenvolvimento, teste e produ√ß√£o. Ajudando a resolver o famoso problema: "Ah, na minha m√°quina funciona", uma vez que o ambiente de desenvolvimento ser√° o mesmo de teste e tamb√©m de produ√ß√£o.

- Acesse o [link](https://www.docker.com/get-started) e baixe o execut√°vel de acordo com seu Sistema Operacional.

- Para come√ßar, registre-se no [Docker Hub](https://hub.docker.com/signup), essencial para baixar imagens e autenticar-se no Docker CLI. Em seguida, acesse o Docker instalado e fa√ßa login inserindo suas credenciais.

**Execute o codigo a seguir** 

- Criando a imagem do projeto
```bash
$ docker build -t nodejs/chatbot .
```

- Criando o container do projeto
```bash
$ docker run -p 3000:3000 -d nodejs/chatbot
```

- Pare o container do projeto (Substitua o **ID** pelo id do container criado)
```bash
$ docker stop ID
```

- Inicia o container do projeto (Substitua o **ID** pelo id do container criado)
```bash
$ docker start ID
```

#### üé≤ Executar direto na M√°quina local

#### Instale as dependencias
```bash
$ npm i

```
#### Execute o projeto
```bash
$ npm start
```

 <details><summary> Detalhe do Layout </summary>
<p>

  #### Tela de Cria√ß√£o do Apelido do Usu√°rio do Chat
  ![image](https://github.com/KellySoares/chat-nodejs-llama2/assets/56278384/bc598921-1c1b-47f8-99cf-d3fedea666e6)

  #### Tela do Chat
  ![image](https://github.com/KellySoares/chat-nodejs-llama2/assets/56278384/2ed61309-48b8-46ea-8c7f-2e10c6d16ced)

</details> </p>
